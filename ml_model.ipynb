{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, GlobalMaxPooling1D\n",
    "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH= 30\n",
    "MAX_VOCAB_SIZE =20000\n",
    "EMBEDDING_DIM=100\n",
    "VALIDATION_SPLIT =0.2\n",
    "BATCH_SIZE =128\n",
    "EPOCHS =10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = {}\n",
    "with open (os.path.join(\"glove.6B.100d.txt\"), encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values=line.split()\n",
    "        word=values[0]\n",
    "        vec = np.asarray(values[1:], dtype=\"float32\")\n",
    "        word2vec[word] =vec    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>askreddit</th>\n",
       "      <th>worldnews</th>\n",
       "      <th>funny</th>\n",
       "      <th>gaming</th>\n",
       "      <th>news</th>\n",
       "      <th>movies</th>\n",
       "      <th>tifu</th>\n",
       "      <th>mildlyinteresting</th>\n",
       "      <th>explainlikeimfive</th>\n",
       "      <th>...</th>\n",
       "      <th>todayilearned</th>\n",
       "      <th>jokes</th>\n",
       "      <th>aww</th>\n",
       "      <th>videos</th>\n",
       "      <th>lifeprotips</th>\n",
       "      <th>twoxchromosomes</th>\n",
       "      <th>oldschoolcool</th>\n",
       "      <th>art</th>\n",
       "      <th>dataisbeautiful</th>\n",
       "      <th>amitheasshole</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Chris Rock is performing a standup gig tonight...</td>\n",
       "      <td>Zelenskyy says 'horrors' of Russian invasion c...</td>\n",
       "      <td>Will Smith arrives at the Oscars after party:</td>\n",
       "      <td>A player in Elden Ring named \"Let me solo her\"...</td>\n",
       "      <td>Jackson confirmed as first Black female high c...</td>\n",
       "      <td>Hello, I’m Nicolas Cage and welcome to Ask Me ...</td>\n",
       "      <td>TIFU by thinking my son was having gay sex whe...</td>\n",
       "      <td>This pet shop don’t sell bunnies at Easter</td>\n",
       "      <td>ELI5: How do “hostile takeovers” work? Is ther...</td>\n",
       "      <td>...</td>\n",
       "      <td>TIL that after Lance Armstrong was stripped of...</td>\n",
       "      <td>We should have a TV show where illegal immigra...</td>\n",
       "      <td>When your cat trusts you so much that she brin...</td>\n",
       "      <td>Jim Carrey on Will Smith assaulting Chris Rock...</td>\n",
       "      <td>LPT If you're planning on visiting San Francis...</td>\n",
       "      <td>40% of teen pregnancies in 15 y/o girls involv...</td>\n",
       "      <td>Willem Dafoe 1981</td>\n",
       "      <td>Cheers!, Me, Digital, 2022</td>\n",
       "      <td>[OC] I wondered why girls put their Snapchat i...</td>\n",
       "      <td>AITA for getting mad my artist hid their initi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What is your best insult, WITHOUT using curse ...</td>\n",
       "      <td>Russian warship Moskva has sunk - state media ...</td>\n",
       "      <td>My wife, using her violin as weaponized sarcasm.</td>\n",
       "      <td>One of my favourite Easter Eggs in gaming</td>\n",
       "      <td>DC Police Find 5 Fetuses in Home of Anti-Abort...</td>\n",
       "      <td>Gilbert Gottfried, Comedian and ‘Aladdin’ Star...</td>\n",
       "      <td>TIFU when my mother caught me eating my girlfr...</td>\n",
       "      <td>My dad wrote Isaac Asimov a question when he w...</td>\n",
       "      <td>ELI5: Why does the economy require to keep gro...</td>\n",
       "      <td>...</td>\n",
       "      <td>TIL dogs \"play sneeze\" when they're feeling ex...</td>\n",
       "      <td>A lesbian named Linda went to the beach. She u...</td>\n",
       "      <td>Camping with Golden Retrievers</td>\n",
       "      <td>Johnny Depp’s reaction to the court finally ge...</td>\n",
       "      <td>LPT If you feel tired and want to sleep with k...</td>\n",
       "      <td>U.S. Congresswoman Marjorie Taylor Greene defi...</td>\n",
       "      <td>My grandma &amp; grandpa in 1955</td>\n",
       "      <td>Sis, get out the way I want to see the rainbow...</td>\n",
       "      <td>[OC] Which media organizations are trusted mor...</td>\n",
       "      <td>AITA for embarrassing my FIL after I repeatedl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                          askreddit  \\\n",
       "0           0  Chris Rock is performing a standup gig tonight...   \n",
       "1           1  What is your best insult, WITHOUT using curse ...   \n",
       "\n",
       "                                           worldnews  \\\n",
       "0  Zelenskyy says 'horrors' of Russian invasion c...   \n",
       "1  Russian warship Moskva has sunk - state media ...   \n",
       "\n",
       "                                              funny  \\\n",
       "0     Will Smith arrives at the Oscars after party:   \n",
       "1  My wife, using her violin as weaponized sarcasm.   \n",
       "\n",
       "                                              gaming  \\\n",
       "0  A player in Elden Ring named \"Let me solo her\"...   \n",
       "1          One of my favourite Easter Eggs in gaming   \n",
       "\n",
       "                                                news  \\\n",
       "0  Jackson confirmed as first Black female high c...   \n",
       "1  DC Police Find 5 Fetuses in Home of Anti-Abort...   \n",
       "\n",
       "                                              movies  \\\n",
       "0  Hello, I’m Nicolas Cage and welcome to Ask Me ...   \n",
       "1  Gilbert Gottfried, Comedian and ‘Aladdin’ Star...   \n",
       "\n",
       "                                                tifu  \\\n",
       "0  TIFU by thinking my son was having gay sex whe...   \n",
       "1  TIFU when my mother caught me eating my girlfr...   \n",
       "\n",
       "                                   mildlyinteresting  \\\n",
       "0         This pet shop don’t sell bunnies at Easter   \n",
       "1  My dad wrote Isaac Asimov a question when he w...   \n",
       "\n",
       "                                   explainlikeimfive  ...  \\\n",
       "0  ELI5: How do “hostile takeovers” work? Is ther...  ...   \n",
       "1  ELI5: Why does the economy require to keep gro...  ...   \n",
       "\n",
       "                                       todayilearned  \\\n",
       "0  TIL that after Lance Armstrong was stripped of...   \n",
       "1  TIL dogs \"play sneeze\" when they're feeling ex...   \n",
       "\n",
       "                                               jokes  \\\n",
       "0  We should have a TV show where illegal immigra...   \n",
       "1  A lesbian named Linda went to the beach. She u...   \n",
       "\n",
       "                                                 aww  \\\n",
       "0  When your cat trusts you so much that she brin...   \n",
       "1                     Camping with Golden Retrievers   \n",
       "\n",
       "                                              videos  \\\n",
       "0  Jim Carrey on Will Smith assaulting Chris Rock...   \n",
       "1  Johnny Depp’s reaction to the court finally ge...   \n",
       "\n",
       "                                         lifeprotips  \\\n",
       "0  LPT If you're planning on visiting San Francis...   \n",
       "1  LPT If you feel tired and want to sleep with k...   \n",
       "\n",
       "                                     twoxchromosomes  \\\n",
       "0  40% of teen pregnancies in 15 y/o girls involv...   \n",
       "1  U.S. Congresswoman Marjorie Taylor Greene defi...   \n",
       "\n",
       "                  oldschoolcool  \\\n",
       "0             Willem Dafoe 1981   \n",
       "1  My grandma & grandpa in 1955   \n",
       "\n",
       "                                                 art  \\\n",
       "0                         Cheers!, Me, Digital, 2022   \n",
       "1  Sis, get out the way I want to see the rainbow...   \n",
       "\n",
       "                                     dataisbeautiful  \\\n",
       "0  [OC] I wondered why girls put their Snapchat i...   \n",
       "1  [OC] Which media organizations are trusted mor...   \n",
       "\n",
       "                                       amitheasshole  \n",
       "0  AITA for getting mad my artist hid their initi...  \n",
       "1  AITA for embarrassing my FIL after I repeatedl...  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"popular_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>askreddit</th>\n",
       "      <th>worldnews</th>\n",
       "      <th>funny</th>\n",
       "      <th>gaming</th>\n",
       "      <th>news</th>\n",
       "      <th>movies</th>\n",
       "      <th>tifu</th>\n",
       "      <th>mildlyinteresting</th>\n",
       "      <th>explainlikeimfive</th>\n",
       "      <th>...</th>\n",
       "      <th>todayilearned</th>\n",
       "      <th>jokes</th>\n",
       "      <th>aww</th>\n",
       "      <th>videos</th>\n",
       "      <th>lifeprotips</th>\n",
       "      <th>twoxchromosomes</th>\n",
       "      <th>oldschoolcool</th>\n",
       "      <th>art</th>\n",
       "      <th>dataisbeautiful</th>\n",
       "      <th>amitheasshole</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chris Rock is performing a standup gig tonight...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is your best insult, WITHOUT using curse ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Zelenskyy says 'horrors' of Russian invasion c...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Russian warship Moskva has sunk - state media ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Will Smith arrives at the Oscars after party:</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  askreddit  worldnews  \\\n",
       "0  Chris Rock is performing a standup gig tonight...        1.0        0.0   \n",
       "1  What is your best insult, WITHOUT using curse ...        1.0        0.0   \n",
       "2  Zelenskyy says 'horrors' of Russian invasion c...        0.0        1.0   \n",
       "3  Russian warship Moskva has sunk - state media ...        0.0        1.0   \n",
       "4      Will Smith arrives at the Oscars after party:        0.0        0.0   \n",
       "\n",
       "   funny  gaming  news  movies  tifu  mildlyinteresting  explainlikeimfive  \\\n",
       "0    0.0     0.0   0.0     0.0   0.0                0.0                0.0   \n",
       "1    0.0     0.0   0.0     0.0   0.0                0.0                0.0   \n",
       "2    0.0     0.0   0.0     0.0   0.0                0.0                0.0   \n",
       "3    0.0     0.0   0.0     0.0   0.0                0.0                0.0   \n",
       "4    1.0     0.0   0.0     0.0   0.0                0.0                0.0   \n",
       "\n",
       "   ...  todayilearned  jokes  aww  videos  lifeprotips  twoxchromosomes  \\\n",
       "0  ...            0.0    0.0  0.0     0.0          0.0              0.0   \n",
       "1  ...            0.0    0.0  0.0     0.0          0.0              0.0   \n",
       "2  ...            0.0    0.0  0.0     0.0          0.0              0.0   \n",
       "3  ...            0.0    0.0  0.0     0.0          0.0              0.0   \n",
       "4  ...            0.0    0.0  0.0     0.0          0.0              0.0   \n",
       "\n",
       "   oldschoolcool  art  dataisbeautiful  amitheasshole  \n",
       "0            0.0  0.0              0.0            0.0  \n",
       "1            0.0  0.0              0.0            0.0  \n",
       "2            0.0  0.0              0.0            0.0  \n",
       "3            0.0  0.0              0.0            0.0  \n",
       "4            0.0  0.0              0.0            0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.DataFrame()\n",
    "train['title'] = []\n",
    "for i in df.columns[1:]:\n",
    "    train[i] = []\n",
    "\n",
    "for label in df.columns[1:]:\n",
    "    for sentence in df[label]:\n",
    "        train = train.append({'title': sentence, label:1},ignore_index=True)\n",
    "        train = train.fillna(0)\n",
    "\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_labels = ['askreddit',\n",
    "'worldnews',\n",
    "'funny',\n",
    "'gaming',\n",
    "'news',\n",
    "'movies',\n",
    "'tifu',\n",
    "'mildlyinteresting',\n",
    "'explainlikeimfive',\n",
    "'pics',\n",
    "'todayilearned',\n",
    "'jokes',\n",
    "'aww',\n",
    "'videos',\n",
    "'lifeprotips',\n",
    "'twoxchromosomes',\n",
    "'oldschoolcool',\n",
    "'art',\n",
    "'dataisbeautiful',\n",
    "'amitheasshole']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing and Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "sentences = train[\"title\"].fillna(\"NO_TITLE_EMPTY\").values\n",
    "targets = train[possible_labels].values\n",
    "\n",
    "tokenizer= Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "sequences = tokenizer.texts_to_sequences(sentences)\n",
    "#sequences\n",
    "#tokenizer.word_index\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the Data Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max sequence length: 53\n",
      "min sequence length: 3\n",
      "median sequence length: 15\n",
      "max word index: 462\n",
      "Found 462 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "print(\"max sequence length:\", max(len(s) for s in sequences))\n",
    "print(\"min sequence length:\", min(len(s) for s in sequences))\n",
    "s = sorted(len(s) for s in sequences)\n",
    "print(\"median sequence length:\", s[len(s) // 2])\n",
    "\n",
    "print(\"max word index:\", max(max(seq) for seq in sequences if len(seq) > 0))\n",
    "\n",
    "\n",
    "# get word -> integer mapping\n",
    "word2idx = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word2idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = min(MAX_VOCAB_SIZE, len(word2idx) + 1)\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word2idx.items():\n",
    "  if i < MAX_VOCAB_SIZE:\n",
    "    embedding_vector = word2vec.get(word)\n",
    "    if embedding_vector is not None:\n",
    "      # words not found in embedding index will be all zeros.\n",
    "      embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "    num_words,\n",
    "    EMBEDDING_DIM,\n",
    "    weights=[embedding_matrix],\n",
    "    input_length=MAX_SEQUENCE_LENGTH,\n",
    "    trainable=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = Input(shape=(MAX_SEQUENCE_LENGTH,)) #Dimensions\n",
    "\n",
    "x=embedding_layer(input_)\n",
    "\n",
    "x=Conv1D(128,2,activation=\"relu\")(x)\n",
    "x=MaxPooling1D(2)(x)\n",
    "\n",
    "x=Conv1D(128,3,activation=\"relu\")(x)\n",
    "x=MaxPooling1D(3)(x)\n",
    "\n",
    "x=Conv1D(128,3,activation=\"relu\")(x)\n",
    "x=GlobalMaxPooling1D()(x)\n",
    "\n",
    "x=Dense(128,activation=\"relu\")(x)\n",
    "\n",
    "output=Dense(len(possible_labels), activation=\"sigmoid\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(input_, output)\n",
    "model.compile(\n",
    "  loss='binary_crossentropy',\n",
    "  optimizer='rmsprop',\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1/1 [==============================] - 3s 3s/step - loss: 0.7055 - accuracy: 0.0625 - val_loss: 0.5906 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5293 - accuracy: 0.0938 - val_loss: 0.4538 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3269 - accuracy: 0.0625 - val_loss: 0.3617 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2125 - accuracy: 0.0625 - val_loss: 0.3626 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1882 - accuracy: 0.2188 - val_loss: 0.3632 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.1738 - accuracy: 0.4688 - val_loss: 0.3758 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.1658 - accuracy: 0.3438 - val_loss: 0.3811 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1707 - accuracy: 0.4688 - val_loss: 0.3835 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1617 - accuracy: 0.5625 - val_loss: 0.3899 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1619 - accuracy: 0.3125 - val_loss: 0.3819 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "r = model.fit(\n",
    "  data,\n",
    "  targets,\n",
    "  batch_size=BATCH_SIZE,\n",
    "  epochs=EPOCHS,\n",
    "  validation_split=VALIDATION_SPLIT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"WOMAN WOMAN WOMAN WOMAN WOMAN\"\n",
    "test_seq = tokenizer.texts_to_sequences(test_text)\n",
    "test_pad = pad_sequences(test_seq,maxlen=MAX_SEQUENCE_LENGTH)\n",
    "subreddits=model.predict(test_pad)[0].round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(possible_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 askreddit\n",
      "0.5 worldnews\n",
      "0.5 funny\n",
      "0.5 gaming\n",
      "0.5 news\n",
      "0.5 movies\n",
      "0.5 tifu\n",
      "0.5 mildlyinteresting\n",
      "0.5 explainlikeimfive\n",
      "0.5 pics\n",
      "0.5 todayilearned\n",
      "0.5 jokes\n",
      "0.5 aww\n",
      "0.5 videos\n",
      "0.5 lifeprotips\n",
      "0.5 twoxchromosomes\n",
      "0.5 oldschoolcool\n",
      "0.5 art\n",
      "0.5 dataisbeautiful\n",
      "0.5 amitheasshole\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,20):\n",
    "    print(subreddits[i] ,possible_labels[i])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
